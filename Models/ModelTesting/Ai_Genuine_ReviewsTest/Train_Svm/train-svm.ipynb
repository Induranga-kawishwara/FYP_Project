{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d992d3",
   "metadata": {
    "_cell_guid": "d2e72fd7-ca67-40c9-bf5e-f1bc31f0f985",
    "_uuid": "5ee8e8c7-ee07-4dfd-aa10-8a94e233fad4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-20T09:54:29.696936Z",
     "iopub.status.busy": "2025-06-20T09:54:29.696573Z",
     "iopub.status.idle": "2025-06-20T09:57:02.169528Z",
     "shell.execute_reply": "2025-06-20T09:57:02.168566Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 152.477943,
     "end_time": "2025-06-20T09:57:02.171137",
     "exception": false,
     "start_time": "2025-06-20T09:54:29.693194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "#  Configuration \n",
    "BASE = \"C:/Users/indur/OneDrive - University of Westminster/GitHub/FYP_Project/Models/ModelTesting/Ai_Genuine_ReviewsTest\"\n",
    "SEED = 42\n",
    "DATA_SPLIT = f\"{BASE}/DataPreparation/DataSet/\"  \n",
    "MODEL_OUT = f\"{BASE}/Train_Svm/svm_model_with_cm.joblib\"\n",
    "CV_FOLDS = 5\n",
    "DROP_TOP_N = 100\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "matplotlib.use(\"Agg\")  # Non-interactive backend for plots\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "#  0. Load your splits \n",
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(DATA_SPLIT, \"train.csv\"))\n",
    "    val_df = pd.read_csv(os.path.join(DATA_SPLIT, \"val.csv\"))\n",
    "    test_df = pd.read_csv(os.path.join(DATA_SPLIT, \"test.csv\"))\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Data files not found in {DATA_SPLIT}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Checking for missing values\")\n",
    "for name, df in [(\"Train\", train_df), (\"Val\", val_df), (\"Test\", test_df)]:\n",
    "    missing = df.isna().sum()\n",
    "    if missing.any():\n",
    "        print(f\"{name} missing values:\\n{missing}\")\n",
    "\n",
    "# Verify label classes\n",
    "print(f\"Unique labels: {np.unique(train_df.label)}\")\n",
    "\n",
    "#  1. Sanity checks \n",
    "def check_overlap(a, b, name_a, name_b):\n",
    "    overlap = len(set(a) & set(b))\n",
    "    print(f\"{name_a} / {name_b} overlap: {overlap}\")\n",
    "    return overlap\n",
    "\n",
    "print(\"Checking for leaks between splits\")\n",
    "check_overlap(train_df.clean_review, val_df.clean_review, \"Train\", \"Val\")\n",
    "check_overlap(train_df.clean_review, test_df.clean_review, \"Train\", \"Test\")\n",
    "check_overlap(val_df.clean_review, test_df.clean_review, \"Val\", \"Test\")\n",
    "\n",
    "#  2. Build TF-IDF (full) \n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(train_df.clean_review)\n",
    "X_val = tfidf.transform(val_df.clean_review)\n",
    "X_test = tfidf.transform(test_df.clean_review)\n",
    "\n",
    "y_train = train_df.label\n",
    "y_val = val_df.label\n",
    "y_test = test_df.label\n",
    "\n",
    "print(f\"TF-IDF vocabulary size: {len(tfidf.get_feature_names_out())}\")\n",
    "\n",
    "#  3. k-Fold Cross-Validation \n",
    "svc = SVC(kernel=\"linear\", C=1.0, random_state=SEED, max_iter=1000)\n",
    "cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=SEED)\n",
    "cv_scores_acc = cross_val_score(svc, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "cv_scores_f1 = cross_val_score(svc, X_train, y_train, cv=cv, scoring=\"f1\")\n",
    "print(f\"{CV_FOLDS}-fold CV accuracy: {cv_scores_acc.mean():.3f} ± {cv_scores_acc.std():.3f}\")\n",
    "print(f\"{CV_FOLDS}-fold CV F1 score: {cv_scores_f1.mean():.3f} ± {cv_scores_f1.std():.3f}\")\n",
    "\n",
    "#  4. Train on full train split \n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "#  5. Evaluation helper \n",
    "def eval_and_plot(X, y, title):\n",
    "    preds = svc.predict(X)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    f1 = f1_score(y, preds, average=\"binary\")  \n",
    "    print(f\"\\n{title}  Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "    print(classification_report(y, preds, target_names=[\"genuine\", \"ai\"]))\n",
    "\n",
    "    # Confusion matrix plot\n",
    "    cm = confusion_matrix(y, preds)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "        xticklabels=[\"genuine\", \"ai\"],\n",
    "        yticklabels=[\"genuine\", \"ai\"]\n",
    "    )\n",
    "    plt.title(f\"{title} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.savefig(f\"{title.lower()}_cm.png\")\n",
    "    plt.close()\n",
    "\n",
    "#  6. Plot for Validation and Test \n",
    "eval_and_plot(X_val, y_val, \"Validation\")\n",
    "eval_and_plot(X_test, y_test, \"Test\")\n",
    "\n",
    "#  7. Feature-Ablation Sanity Check \n",
    "coefs = np.abs(svc.coef_.toarray()).ravel()\n",
    "top_idx = np.argsort(coefs)[::-1][:DROP_TOP_N]\n",
    "mask = np.ones(len(coefs), dtype=bool)\n",
    "mask[top_idx] = False\n",
    "\n",
    "# Log top features for interpretability\n",
    "top_features = tfidf.get_feature_names_out()[top_idx]\n",
    "print(f\"Top {DROP_TOP_N} features dropped: {top_features[:10]}\")\n",
    "\n",
    "svc_ablate = SVC(kernel=\"linear\", C=1.0, random_state=SEED, max_iter=1000)\n",
    "svc_ablate.fit(X_train[:, mask], y_train)\n",
    "ablate_acc = accuracy_score(y_val, svc_ablate.predict(X_val[:, mask]))\n",
    "print(f\"\\nAfter dropping top {DROP_TOP_N} features, Val Acc: {ablate_acc:.4f}\")\n",
    "\n",
    "#  8. Save final model \n",
    "os.makedirs(os.path.dirname(MODEL_OUT), exist_ok=True)\n",
    "try:\n",
    "    joblib.dump({\"tfidf\": tfidf, \"model\": svc}, MODEL_OUT)\n",
    "    print(f\"Saved TF-IDF + SVM (with CM plots) to {MODEL_OUT}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 246490237,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 158.361636,
   "end_time": "2025-06-20T09:57:02.994182",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-20T09:54:24.632546",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
